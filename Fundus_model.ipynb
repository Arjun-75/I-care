{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Ensure required packages are installed\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Helper to install missing packages\n",
        "def install_package(pkg):\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
        "\n",
        "# Check for GPU availability\n",
        "def check_gpu_availability():\n",
        "    gpu_info = {}\n",
        "\n",
        "    # Check CUDA\n",
        "    try:\n",
        "        import torch\n",
        "        gpu_info['torch_cuda'] = torch.cuda.is_available()\n",
        "        if gpu_info['torch_cuda']:\n",
        "            gpu_info['cuda_devices'] = torch.cuda.device_count()\n",
        "            gpu_info['cuda_device_name'] = torch.cuda.get_device_name(0)\n",
        "    except ImportError:\n",
        "        gpu_info['torch_cuda'] = False\n",
        "\n",
        "    # Check CuPy (for cuML)\n",
        "    try:\n",
        "        import cupy\n",
        "        gpu_info['cupy'] = True\n",
        "    except ImportError:\n",
        "        gpu_info['cupy'] = False\n",
        "\n",
        "    return gpu_info\n"
      ],
      "metadata": {
        "id": "xqRMwc9X5tYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install GPU packages if available\n",
        "def setup_gpu_packages():\n",
        "    gpu_info = check_gpu_availability()\n",
        "    packages_installed = {}\n",
        "\n",
        "    # Install PyTorch if not available\n",
        "    if not gpu_info.get('torch_cuda', False):\n",
        "        try:\n",
        "            print(\"Installing PyTorch with CUDA support...\")\n",
        "            install_package('torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118')\n",
        "            packages_installed['torch'] = True\n",
        "        except:\n",
        "            print(\"Failed to install PyTorch with CUDA. Installing CPU version...\")\n",
        "            install_package('torch torchvision torchaudio')\n",
        "            packages_installed['torch'] = False\n",
        "\n",
        "    # Try to install cuML (RAPIDS)\n",
        "    try:\n",
        "        import cuml\n",
        "        packages_installed['cuml'] = True\n",
        "    except ImportError:\n",
        "        try:\n",
        "            print(\"Installing cuML for GPU acceleration...\")\n",
        "            install_package('cuml-cu11')\n",
        "            packages_installed['cuml'] = True\n",
        "        except:\n",
        "            print(\"cuML installation failed. Will use CPU alternatives.\")\n",
        "            packages_installed['cuml'] = False\n",
        "\n",
        "    # Install XGBoost with GPU support\n",
        "    try:\n",
        "        import xgboost as xgb\n",
        "        # Check if GPU support is available\n",
        "        packages_installed['xgb_gpu'] = 'gpu' in str(xgb.XGBClassifier().get_params())\n",
        "    except ImportError:\n",
        "        try:\n",
        "            print(\"Installing XGBoost with GPU support...\")\n",
        "            install_package('xgboost[gpu]')\n",
        "            packages_installed['xgb_gpu'] = True\n",
        "        except:\n",
        "            install_package('xgboost')\n",
        "            packages_installed['xgb_gpu'] = False\n",
        "\n",
        "    # Install LightGBM with GPU support\n",
        "    try:\n",
        "        import lightgbm\n",
        "        packages_installed['lgb_gpu'] = True\n",
        "    except ImportError:\n",
        "        try:\n",
        "            print(\"Installing LightGBM with GPU support...\")\n",
        "            install_package('lightgbm --install-option=--gpu')\n",
        "            packages_installed['lgb_gpu'] = True\n",
        "        except:\n",
        "            install_package('lightgbm')\n",
        "            packages_installed['lgb_gpu'] = False\n",
        "\n",
        "    # Install CatBoost (has built-in GPU support)\n",
        "    try:\n",
        "        import catboost\n",
        "        packages_installed['catboost'] = True\n",
        "    except ImportError:\n",
        "        print(\"Installing CatBoost...\")\n",
        "        install_package('catboost')\n",
        "        packages_installed['catboost'] = True\n",
        "\n",
        "    return packages_installed\n",
        "\n",
        "# Setup packages\n",
        "gpu_packages = setup_gpu_packages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knvc8tS1B8lg",
        "outputId": "92ab77a0-b24b-4197-9df1-08e51088d3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing CatBoost...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, make_scorer\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# GPU-specific imports\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from torch.utils.data import DataLoader, TensorDataset\n",
        "    TORCH_AVAILABLE = torch.cuda.is_available()\n",
        "    print(f\"PyTorch CUDA available: {TORCH_AVAILABLE}\")\n",
        "except ImportError:\n",
        "    TORCH_AVAILABLE = False\n",
        "    print(\"PyTorch not available\")\n",
        "\n",
        "try:\n",
        "    import cuml\n",
        "    from cuml.ensemble import RandomForestClassifier as cuRF\n",
        "    from cuml.preprocessing import StandardScaler as cuScaler\n",
        "    from cuml.model_selection import train_test_split as cu_train_test_split\n",
        "    CUML_AVAILABLE = True\n",
        "    print(\"cuML available for GPU acceleration\")\n",
        "except ImportError:\n",
        "    CUML_AVAILABLE = False\n",
        "    print(\"cuML not available - using CPU alternatives\")\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGB_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    LGB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LGB_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import catboost as cb\n",
        "    CATBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    CATBOOST_AVAILABLE = False\n",
        "\n",
        "# Imbalanced learning imports\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
        "    from imblearn.combine import SMOTETomek\n",
        "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "except ModuleNotFoundError:\n",
        "    print(\"imbalanced-learn not found. Installing...\")\n",
        "    install_package('imbalanced-learn')\n",
        "    from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
        "    from imblearn.combine import SMOTETomek\n",
        "    from imblearn.pipeline import Pipeline as ImbPipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7FpsFqTCAq6",
        "outputId": "ab790e41-0cf5-408f-e088-9ed7cd1306c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch CUDA available: True\n",
            "cuML available for GPU acceleration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# GPU-Accelerated Fraud Detection - Production Ready\n",
        "# ============================================================================\n",
        "\n",
        "class GPUNeuralNetwork(nn.Module):\n",
        "    \"\"\"GPU-accelerated neural network for fraud detection\"\"\"\n",
        "    def __init__(self, input_size, hidden_sizes=[512, 256, 128], dropout_rate=0.3):\n",
        "        super(GPUNeuralNetwork, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "\n",
        "        for hidden_size in hidden_sizes:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_size, hidden_size),\n",
        "                nn.BatchNorm1d(hidden_size),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ])\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        layers.append(nn.Linear(prev_size, 1))\n",
        "        layers.append(nn.Sigmoid())\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class FraudDetectorGPU:\n",
        "    def __init__(self, device=None):\n",
        "        if device is None:\n",
        "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        else:\n",
        "            self.device = device\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "\n",
        "    def fit(self, X, y, epochs=100, batch_size=1024, learning_rate=0.001):\n",
        "        \"\"\"Train the neural network\"\"\"\n",
        "        # Scale features\n",
        "        if CUML_AVAILABLE:\n",
        "            self.scaler = cuScaler()\n",
        "        else:\n",
        "            self.scaler = RobustScaler()\n",
        "\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Convert to tensors\n",
        "        X_tensor = torch.FloatTensor(X_scaled).to(self.device)\n",
        "        y_tensor = torch.FloatTensor(y.values.reshape(-1, 1)).to(self.device)\n",
        "\n",
        "        # Create model\n",
        "        self.model = GPUNeuralNetwork(X.shape[1]).to(self.device)\n",
        "\n",
        "        # Loss and optimizer\n",
        "        criterion = nn.BCELoss()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Training loop\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        self.model.train()\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                optimizer.zero_grad()\n",
        "                predictions = self.model(batch_X)\n",
        "                loss = criterion(predictions, batch_y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(dataloader):.4f}')\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predict probabilities\"\"\"\n",
        "        self.model.eval()\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        X_tensor = torch.FloatTensor(X_scaled).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X_tensor).cpu().numpy()\n",
        "\n",
        "        # Return probabilities for both classes\n",
        "        probs_class_0 = 1 - predictions.flatten()\n",
        "        probs_class_1 = predictions.flatten()\n",
        "        return np.column_stack([probs_class_0, probs_class_1])\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        \"\"\"Make predictions\"\"\"\n",
        "        probs = self.predict_proba(X)[:, 1]\n",
        "        return (probs >= threshold).astype(int)"
      ],
      "metadata": {
        "id": "Lt6ohjRjCHPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_or_generate_data(path='Fraud.csv'):\n",
        "    \"\"\"Load or generate fraud detection dataset\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        print(\"✓ Loaded real dataset\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️  Sample dataset created\")\n",
        "        np.random.seed(42)\n",
        "        n = 200000\n",
        "        steps = np.random.randint(1, 745, n)\n",
        "        types = np.random.choice(\n",
        "            ['CASH-IN', 'CASH-OUT', 'DEBIT', 'PAYMENT', 'TRANSFER'],\n",
        "            n, p=[0.2, 0.15, 0.1, 0.35, 0.2]\n",
        "        )\n",
        "        amounts = np.clip(np.random.lognormal(5, 2, n), 0.01, 1e6)\n",
        "        old_org = np.clip(np.random.lognormal(7, 1.5, n), 0, 5e5)\n",
        "        fraud_prob = np.where(types == 'TRANSFER', 0.008,\n",
        "                              np.where(types == 'CASH-OUT', 0.004, 0.001))\n",
        "        high_amt = amounts > np.percentile(amounts, 95)\n",
        "        night = (steps % 24) < 6\n",
        "        weekend = ((steps // 24) % 7) >= 5\n",
        "        fraud_prob *= (1 + high_amt * 3 + night * 2 + weekend * 1.5)\n",
        "        is_fraud = np.random.binomial(1, fraud_prob)\n",
        "        new_org = np.clip(\n",
        "            old_org + np.where(np.isin(types, ['CASH-OUT', 'TRANSFER', 'PAYMENT']), -amounts, amounts),\n",
        "            0, None\n",
        "        )\n",
        "        is_merchant = np.random.choice([0, 1], n, p=[0.7, 0.3])\n",
        "        old_dest = np.where(is_merchant, 0,\n",
        "                            np.clip(np.random.lognormal(6, 1.2, n), 0, None))\n",
        "        new_dest = np.where(is_merchant, 0,\n",
        "                            np.where(np.isin(types, ['TRANSFER', 'PAYMENT']), old_dest + amounts, old_dest))\n",
        "        df = pd.DataFrame({\n",
        "            'step': steps,\n",
        "            'type': types,\n",
        "            'amount': amounts,\n",
        "            'nameOrig': ['C' + str(i) for i in range(n)],\n",
        "            'oldbalanceOrg': old_org,\n",
        "            'newbalanceOrig': new_org,\n",
        "            'nameDest': [\n",
        "                'M' + str(i) if is_merchant[i] else 'C' + str(i + n)\n",
        "                for i in range(n)\n",
        "            ],\n",
        "            'oldbalanceDest': old_dest,\n",
        "            'newbalanceDest': new_dest,\n",
        "            'isFraud': is_fraud\n",
        "        })\n",
        "        df['isFlaggedFraud'] = (\n",
        "            (df['type'] == 'TRANSFER') & (df['amount'] > 200000)\n",
        "        ).astype(int)\n",
        "    return df\n",
        "\n",
        "def preprocess(df):\n",
        "    \"\"\"Preprocess the dataset\"\"\"\n",
        "    # Handle missing values\n",
        "    if df.isnull().sum().sum() > 0:\n",
        "        df = df.fillna(0)\n",
        "\n",
        "    # Merchant flags\n",
        "    df['is_merchant_dest'] = df['nameDest'].str.startswith('M').astype(int)\n",
        "    df['is_merchant_orig'] = df['nameOrig'].str.startswith('M').astype(int)\n",
        "\n",
        "    # Zero balances for merchant destinations\n",
        "    mask = df['is_merchant_dest'] == 1\n",
        "    df.loc[mask, ['oldbalanceDest', 'newbalanceDest']] = 0\n",
        "    return df\n",
        "\n",
        "def engineer_features(df):\n",
        "    \"\"\"Engineer features for fraud detection\"\"\"\n",
        "    # Time features\n",
        "    df['hour_of_day'] = df['step'] % 24\n",
        "    df['day_of_week'] = ((df['step'] // 24) % 7)\n",
        "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "    df['is_night'] = ((df['hour_of_day'] >= 22) | (df['hour_of_day'] <= 6)).astype(int)\n",
        "\n",
        "    # Amount features\n",
        "    df['amount_log'] = np.log1p(df['amount'])\n",
        "    df['is_large_amount'] = (df['amount'] > df['amount'].quantile(0.95)).astype(int)\n",
        "    df['is_round_amount'] = (df['amount'] % 1000 == 0).astype(int)\n",
        "\n",
        "    # Balance ratios\n",
        "    df['orig_amt_ratio'] = df['oldbalanceOrg'] / (df['amount'] + 1)\n",
        "    df['dest_amt_ratio'] = df['oldbalanceDest'] / (df['amount'] + 1)\n",
        "\n",
        "    # Velocity features\n",
        "    df_sorted = df.sort_values(['nameOrig', 'step'])\n",
        "    df['time_diff'] = df_sorted.groupby('nameOrig')['step'].diff().fillna(999)\n",
        "    df['rapid_txn'] = (df['time_diff'] <= 2).astype(int)\n",
        "\n",
        "    # Type encoding\n",
        "    df['type_enc'] = LabelEncoder().fit_transform(df['type'])\n",
        "    return df\n",
        "\n",
        "def feature_selection(df):\n",
        "    \"\"\"Select best features using multiple methods\"\"\"\n",
        "    from sklearn.feature_selection import SelectKBest, f_classif, RFE, SelectFromModel\n",
        "    from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "    target = df['isFraud']\n",
        "    features = [c for c in df.columns if c not in ['isFraud','nameOrig','nameDest','type']]\n",
        "    X = df[features]\n",
        "\n",
        "    # ANOVA F-test\n",
        "    anova_selector = SelectKBest(f_classif, k=20).fit(X, target)\n",
        "    anova_features = set(X.columns[anova_selector.get_support()])\n",
        "\n",
        "    # Tree-based selection\n",
        "    tree_selector = ExtraTreesClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1)\n",
        "    tree_selector.fit(X, target)\n",
        "    tree_model = SelectFromModel(tree_selector, prefit=True, threshold='median')\n",
        "    tree_features = set(X.columns[tree_model.get_support()])\n",
        "\n",
        "    # RFE selection\n",
        "    rfe_selector = RFE(\n",
        "        ExtraTreesClassifier(n_estimators=50, class_weight='balanced', n_jobs=-1),\n",
        "        n_features_to_select=20\n",
        "    ).fit(X, target)\n",
        "    rfe_features = set(X.columns[rfe_selector.support_])\n",
        "\n",
        "    # Combine selections (majority vote)\n",
        "    selected_features = (anova_features & tree_features) | \\\n",
        "                       (anova_features & rfe_features) | \\\n",
        "                       (tree_features & rfe_features)\n",
        "\n",
        "    return list(selected_features)\n",
        "\n",
        "def get_gpu_models():\n",
        "    \"\"\"Get GPU-accelerated models\"\"\"\n",
        "    models = {}\n",
        "\n",
        "    # XGBoost with GPU\n",
        "    if XGB_AVAILABLE:\n",
        "        try:\n",
        "            models['XGB_GPU'] = xgb.XGBClassifier(\n",
        "                tree_method='gpu_hist',\n",
        "                gpu_id=0,\n",
        "                random_state=42,\n",
        "                eval_metric='logloss',\n",
        "                use_label_encoder=False\n",
        "            )\n",
        "            print(\"✓ XGBoost GPU enabled\")\n",
        "        except:\n",
        "            models['XGB'] = xgb.XGBClassifier(\n",
        "                random_state=42,\n",
        "                eval_metric='logloss',\n",
        "                use_label_encoder=False\n",
        "            )\n",
        "            print(\"⚠️  XGBoost GPU failed, using CPU\")\n",
        "\n",
        "    # LightGBM with GPU\n",
        "    if LGB_AVAILABLE:\n",
        "        try:\n",
        "            models['LGB_GPU'] = lgb.LGBMClassifier(\n",
        "                device='gpu',\n",
        "                random_state=42,\n",
        "                verbosity=-1\n",
        "            )\n",
        "            print(\"✓ LightGBM GPU enabled\")\n",
        "        except:\n",
        "            models['LGB'] = lgb.LGBMClassifier(\n",
        "                random_state=42,\n",
        "                verbosity=-1\n",
        "            )\n",
        "            print(\"⚠️  LightGBM GPU failed, using CPU\")\n",
        "\n",
        "    # CatBoost with GPU\n",
        "    if CATBOOST_AVAILABLE:\n",
        "        try:\n",
        "            models['CAT_GPU'] = cb.CatBoostClassifier(\n",
        "                task_type='GPU',\n",
        "                random_state=42,\n",
        "                verbose=False\n",
        "            )\n",
        "            print(\"✓ CatBoost GPU enabled\")\n",
        "        except:\n",
        "            models['CAT'] = cb.CatBoostClassifier(\n",
        "                random_state=42,\n",
        "                verbose=False\n",
        "            )\n",
        "            print(\"⚠️  CatBoost GPU failed, using CPU\")\n",
        "\n",
        "    # cuML Random Forest (if available)\n",
        "    if CUML_AVAILABLE:\n",
        "        models['cuRF'] = cuRF(\n",
        "            n_estimators=100,\n",
        "            random_state=42\n",
        "        )\n",
        "        print(\"✓ cuML Random Forest enabled\")\n",
        "\n",
        "    return models\n"
      ],
      "metadata": {
        "id": "KP2Vv3wfCKek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"=== GPU-Accelerated Fraud Detection System ===\")\n",
        "    print(f\"GPU Packages Status: {gpu_packages}\")\n",
        "\n",
        "    # Load and preprocess data\n",
        "    print(\"\\n1. Loading and preprocessing data...\")\n",
        "    df = load_or_generate_data()\n",
        "    df = preprocess(df)\n",
        "    df = engineer_features(df)\n",
        "\n",
        "    # Feature selection\n",
        "    print(\"\\n2. Selecting features...\")\n",
        "    selected_features = feature_selection(df)\n",
        "    print(f\"Selected {len(selected_features)} features\")\n",
        "\n",
        "    # Prepare data\n",
        "    X = df[selected_features].fillna(0)\n",
        "    y = df['isFraud']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    # Handle class imbalance\n",
        "    print(\"\\n3. Handling class imbalance...\")\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "    print(f\"Balanced training set size: {len(y_train_balanced)}\")\n",
        "\n",
        "    # GPU Neural Network\n",
        "    if TORCH_AVAILABLE:\n",
        "        print(\"\\n4. Training GPU Neural Network...\")\n",
        "        gpu_nn = FraudDetectorGPU()\n",
        "        gpu_nn.fit(X_train_balanced, y_train_balanced, epochs=50, batch_size=2048)\n",
        "\n",
        "        # Evaluate Neural Network\n",
        "        nn_probs = gpu_nn.predict_proba(X_test)[:, 1]\n",
        "        nn_auc = roc_auc_score(y_test, nn_probs)\n",
        "        print(f\"Neural Network Test AUC: {nn_auc:.4f}\")\n",
        "\n",
        "    # GPU Tree-based models\n",
        "    print(\"\\n5. Training GPU Tree Models...\")\n",
        "    gpu_models = get_gpu_models()\n",
        "    trained_models = {}\n",
        "\n",
        "    for name, model in gpu_models.items():\n",
        "        try:\n",
        "            print(f\"Training {name}...\")\n",
        "            model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "            # Evaluate\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                probs = model.predict_proba(X_test)[:, 1]\n",
        "            else:\n",
        "                # For cuML models that might not have predict_proba\n",
        "                preds = model.predict(X_test)\n",
        "                probs = preds\n",
        "\n",
        "            auc = roc_auc_score(y_test, probs)\n",
        "            print(f\"{name} Test AUC: {auc:.4f}\")\n",
        "            trained_models[name] = model\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to train {name}: {str(e)}\")\n",
        "\n",
        "    # Ensemble (if we have multiple models)\n",
        "    if len(trained_models) > 1:\n",
        "        print(\"\\n6. Creating ensemble...\")\n",
        "        # Filter models that work with VotingClassifier\n",
        "        sklearn_models = {}\n",
        "        for name, model in trained_models.items():\n",
        "            if hasattr(model, 'predict_proba') and 'cu' not in name.lower():\n",
        "                sklearn_models[name] = model\n",
        "\n",
        "        if len(sklearn_models) >= 2:\n",
        "            ensemble = VotingClassifier(\n",
        "                estimators=list(sklearn_models.items()),\n",
        "                voting='soft',\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "            # Note: Ensemble needs to be retrained on CPU data\n",
        "            scaler = RobustScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "            ensemble.fit(X_train_scaled, y_train_balanced)\n",
        "            ensemble_probs = ensemble.predict_proba(X_test_scaled)[:, 1]\n",
        "            ensemble_auc = roc_auc_score(y_test, ensemble_probs)\n",
        "            print(f\"Ensemble Test AUC: {ensemble_auc:.4f}\")\n",
        "\n",
        "    # Find optimal threshold\n",
        "    print(\"\\n7. Finding optimal threshold...\")\n",
        "    if TORCH_AVAILABLE:\n",
        "        precision, recall, thresholds = precision_recall_curve(y_test, nn_probs)\n",
        "        f1_scores = 2 * precision * recall / (precision + recall)\n",
        "        optimal_idx = np.nanargmax(f1_scores)\n",
        "        optimal_threshold = thresholds[optimal_idx]\n",
        "        optimal_f1 = f1_scores[optimal_idx]\n",
        "        print(f\"Optimal threshold: {optimal_threshold:.4f}, F1-score: {optimal_f1:.4f}\")\n",
        "\n",
        "    # Save models\n",
        "    print(\"\\n8. Saving models...\")\n",
        "    import joblib\n",
        "\n",
        "    if TORCH_AVAILABLE:\n",
        "        torch.save(gpu_nn.model.state_dict(), 'gpu_fraud_model.pth')\n",
        "        joblib.dump(gpu_nn.scaler, 'gpu_scaler.pkl')\n",
        "        print(\"✓ Saved GPU neural network model\")\n",
        "\n",
        "    for name, model in trained_models.items():\n",
        "        try:\n",
        "            if 'cu' not in name.lower():  # Skip cuML models for joblib\n",
        "                joblib.dump(model, f'{name.lower()}_model.pkl')\n",
        "                print(f\"✓ Saved {name} model\")\n",
        "        except:\n",
        "            print(f\"⚠️  Could not save {name} model\")\n",
        "\n",
        "    print(\"\\n=== Training Complete ===\")\n",
        "    print(\"GPU acceleration status:\")\n",
        "    print(f\"  - PyTorch CUDA: {TORCH_AVAILABLE}\")\n",
        "    print(f\"  - cuML: {CUML_AVAILABLE}\")\n",
        "    print(f\"  - XGBoost GPU: {gpu_packages.get('xgb_gpu', False)}\")\n",
        "    print(f\"  - LightGBM GPU: {gpu_packages.get('lgb_gpu', False)}\")\n",
        "    print(f\"  - CatBoost GPU: {gpu_packages.get('catboost', False)}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Rk0ukTCO-d",
        "outputId": "21612a98-1e3c-4bdf-a598-0e672a6d4fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPU-Accelerated Fraud Detection System ===\n",
            "GPU Packages Status: {'cuml': True, 'xgb_gpu': False, 'lgb_gpu': True, 'catboost': True}\n",
            "\n",
            "1. Loading and preprocessing data...\n",
            "✓ Loaded real dataset\n",
            "\n",
            "2. Selecting features...\n",
            "Selected 20 features\n",
            "\n",
            "3. Handling class imbalance...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AIjeadlwCRiI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}